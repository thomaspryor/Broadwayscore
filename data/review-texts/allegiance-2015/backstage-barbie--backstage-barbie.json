{
  "showId": "allegiance-2015",
  "outletId": "backstage-barbie",
  "outlet": "BackStage Barbie",
  "criticName": "BackStage Barbie",
  "url": "http://backstagebarbie.blogspot.com/2016/01/allegiance-on-broadway.html?m=1",
  "publishDate": null,
  "fullText": null,
  "isFullReview": false,
  "dtliExcerpt": null,
  "originalScore": null,
  "assignedScore": 89,
  "source": "show-score-playwright",
  "dtliThumb": null,
  "dtliUrl": null,
  "bwwExcerpt": null,
  "bwwRoundupUrl": null,
  "showScoreExcerpt": "\"What struck me so much about this piece was not the music, normally my favorite entry point into the musical, but the storytelling...You must see this remarkable show. It is only here for two weeks and it will be one of those shows that if you miss it, you will regret it.\"\n\nRead more",
  "contentTier": "excerpt",
  "contentTierReason": "Only aggregator excerpts available",
  "llmScore": {
    "score": 89,
    "confidence": "medium",
    "range": {
      "low": 84,
      "high": 94
    },
    "bucket": "Rave",
    "thumb": "Up",
    "components": {
      "book": null,
      "music": null,
      "performances": null,
      "direction": null
    },
    "keyPhrases": [
      {
        "quote": "You must see this remarkable show.",
        "sentiment": "neutral",
        "strength": 3
      }
    ],
    "reasoning": "[ensemble-majority] | 3/4 models agree: Rave | Claude: Clear must-see language ('You must see', 'remarkable', 'you will regret it') indicates strong recommendation, but single excerpt warning requires caution about missing context. | GPT-4o: The excerpt contains strong language urging audiences to see the show and suggests it will be regretted if missed, indicating a rave review. However, confidence is low due to the single excerpt warning. | Gemini: The review uses strong positive language such as \"remarkable show\" and \"you must see this\". The critic also states that if you miss it, you will regret it, indicating a very strong recommendation. | Kimi: Single excerpt contains explicit must-see language and superlatives ('remarkable', 'regret it'), but per instructions for single curated excerpts, scores in upper Positive range (80-84) due to limited context.",
    "flags": {
      "hasExplicitRecommendation": false,
      "focusedOnPerformances": false,
      "comparesToPrevious": false,
      "mixedSignals": false
    }
  },
  "llmMetadata": {
    "model": "ensemble:claude-sonnet-4-20250514+gpt-4o+gemini-2.0-flash+moonshotai/kimi-k2.5",
    "scoredAt": "2026-02-07T06:23:27.900Z",
    "promptVersion": "5.2.0",
    "inputTokens": 0,
    "outputTokens": 0,
    "previousScore": null
  },
  "ensembleData": {
    "claudeScore": 88,
    "openaiScore": 90,
    "geminiScore": 90,
    "kimiScore": 83,
    "claudeBucket": "Rave",
    "openaiBucket": "Rave",
    "geminiBucket": "Rave",
    "kimiBucket": "Positive",
    "scoreDelta": 7,
    "thumbsMatch": null,
    "expectedThumb": null,
    "needsReview": false,
    "needsReviewReasons": [],
    "ensembleSource": "ensemble-majority",
    "modelAgreement": "3/4 models agree: Rave"
  }
}
