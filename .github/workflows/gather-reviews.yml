name: Gather Review Data

on:
  # Triggered by update-shows workflow when new shows are discovered
  workflow_dispatch:
    inputs:
      shows:
        description: 'Comma-separated list of show slugs to gather reviews for'
        required: true
        type: string
      parallel_jobs:
        description: 'Number of parallel jobs to split shows across (1=sequential, 2-10=parallel)'
        required: false
        default: '1'
        type: string

permissions:
  contents: write
  issues: write

jobs:
  # Step 1: Split shows into batches for parallel processing
  prepare:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.split.outputs.matrix }}
      job_count: ${{ steps.split.outputs.job_count }}
    steps:
      - name: Split shows into parallel batches
        id: split
        run: |
          SHOWS="${{ inputs.shows }}"
          JOBS=${{ inputs.parallel_jobs }}

          # Validate parallel_jobs is 1-10
          if [ "$JOBS" -lt 1 ] 2>/dev/null || [ "$JOBS" -gt 10 ] 2>/dev/null; then
            JOBS=1
          fi

          # Split comma-separated shows into array
          IFS=',' read -ra SHOW_ARRAY <<< "$SHOWS"
          TOTAL=${#SHOW_ARRAY[@]}

          # Don't use more jobs than shows
          if [ "$JOBS" -gt "$TOTAL" ]; then
            JOBS=$TOTAL
          fi

          echo "Total shows: $TOTAL, parallel jobs: $JOBS"

          # Distribute shows across jobs round-robin
          declare -a BATCHES
          for i in $(seq 0 $((JOBS - 1))); do
            BATCHES[$i]=""
          done

          for i in "${!SHOW_ARRAY[@]}"; do
            BATCH_IDX=$((i % JOBS))
            SHOW=$(echo "${SHOW_ARRAY[$i]}" | xargs)  # trim whitespace
            if [ -n "${BATCHES[$BATCH_IDX]}" ]; then
              BATCHES[$BATCH_IDX]="${BATCHES[$BATCH_IDX]},$SHOW"
            else
              BATCHES[$BATCH_IDX]="$SHOW"
            fi
          done

          # Build JSON matrix
          MATRIX='{"include":['
          FIRST=true
          for i in $(seq 0 $((JOBS - 1))); do
            if [ -n "${BATCHES[$i]}" ]; then
              if [ "$FIRST" = true ]; then
                FIRST=false
              else
                MATRIX="$MATRIX,"
              fi
              # Stagger start: 30s between each job to avoid rate limiting aggregators
              DELAY=$((i * 30))
              MATRIX="$MATRIX{\"batch_id\":$i,\"shows\":\"${BATCHES[$i]}\",\"delay\":$DELAY}"
            fi
          done
          MATRIX="$MATRIX]}"

          echo "Matrix: $MATRIX"
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
          echo "job_count=$JOBS" >> $GITHUB_OUTPUT

  # Step 2: Gather reviews in parallel batches
  gather-reviews:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJson(needs.prepare.outputs.matrix) }}
      fail-fast: false  # Don't cancel other batches if one fails
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install chromium

      - name: Stagger start to avoid rate limiting
        if: matrix.delay > 0
        run: |
          echo "Waiting ${{ matrix.delay }}s before starting (batch ${{ matrix.batch_id }})"
          sleep ${{ matrix.delay }}

      - name: Display shows to process
        run: |
          echo "Batch ${{ matrix.batch_id }}: Gathering review data for shows: ${{ matrix.shows }}"

      - name: Gather reviews
        id: gather
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          BRIGHTDATA_TOKEN: ${{ secrets.BRIGHTDATA_TOKEN }}
          SCRAPINGBEE_API_KEY: ${{ secrets.SCRAPINGBEE_API_KEY }}
        run: |
          SHOWS="${{ matrix.shows }}"

          echo "Processing shows: $SHOWS"
          echo "ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:+SET}"

          # Check if gather-reviews script exists
          if [ -f scripts/gather-reviews.js ]; then
            node scripts/gather-reviews.js --shows="$SHOWS"
          else
            echo "Note: scripts/gather-reviews.js not found"
            echo "Review data will need to be gathered manually"
            echo "shows_processed=0" >> $GITHUB_OUTPUT
            exit 0
          fi

      - name: Validate data before commit
        run: node scripts/validate-data.js
        continue-on-error: true

      - name: Check for changes
        id: git-check
        run: |
          # Check for changes in review-texts or archives directory (NOT reviews.json to avoid conflicts)
          git diff --exit-code data/review-texts/ data/archives/ data/collection-state/ 2>/dev/null || echo "changes=true" >> $GITHUB_OUTPUT
          # Also check for untracked files
          if [ -n "$(git ls-files --others --exclude-standard data/review-texts/ data/archives/)" ]; then
            echo "changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Check for large files
        if: steps.git-check.outputs.changes == 'true'
        uses: ./.github/actions/check-file-sizes

      - name: Commit review data
        if: steps.git-check.outputs.changes == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Only add review-texts and archives (NOT reviews.json to avoid merge conflicts)
          # reviews.json can be rebuilt later from review-texts
          git add data/review-texts/ data/archives/ data/collection-state/

          # Check if there's anything to commit after adding
          if git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          git commit -m "feat: Add review data for ${{ matrix.shows }}"

          # Retry loop for push with rebase (handles parallel workflow conflicts)
          MAX_RETRIES=5
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Push attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"

            # Clean up any unstaged changes (reviews.json, etc.) before rebasing
            git checkout -- . 2>/dev/null || true
            git clean -fd 2>/dev/null || true

            # Pull and rebase, auto-resolve conflicts by preferring our freshly-gathered data
            if git pull --rebase -X theirs origin main; then
              # Try to push
              if git push origin main; then
                echo "Successfully pushed changes"
                exit 0
              fi
            else
              echo "Rebase failed, aborting and retrying..."
              git rebase --abort 2>/dev/null || true
            fi

            RETRY_COUNT=$((RETRY_COUNT + 1))

            if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
              WAIT_TIME=$((10 + RANDOM % 20))  # Random 10-30 second wait to avoid collision
              echo "Waiting $WAIT_TIME seconds before retry..."
              sleep $WAIT_TIME
              # Re-fetch and try again
              git fetch origin main
            fi
          done

          echo "Failed to push after $MAX_RETRIES attempts"
          exit 1

  # Step 3: Scrape supplementary aggregators (Playbill Verdict + NYC Theatre)
  scrape-aggregators:
    needs: [prepare, gather-reviews]
    if: needs.gather-reviews.result == 'success'
    continue-on-error: true
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout (latest, after gather pushes)
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm ci

      - name: Scrape Playbill Verdict for target shows
        env:
          SCRAPINGBEE_API_KEY: ${{ secrets.SCRAPINGBEE_API_KEY }}
          BRIGHTDATA_TOKEN: ${{ secrets.BRIGHTDATA_TOKEN }}
        run: node scripts/scrape-playbill-verdict.js --shows=${{ inputs.shows }}

      - name: Scrape NYC Theatre roundups for target shows
        env:
          SCRAPINGBEE_API_KEY: ${{ secrets.SCRAPINGBEE_API_KEY }}
        run: node scripts/scrape-nyc-theatre-roundups.js --shows=${{ inputs.shows }}

      - name: Commit and push aggregator data
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          git add data/review-texts/ data/aggregator-archive/
          if git diff --staged --quiet; then
            echo "No aggregator changes to commit"
            exit 0
          fi

          git commit -m "data: Add Playbill Verdict + NYC Theatre data for ${{ inputs.shows }}"

          MAX_RETRIES=5
          RETRY_COUNT=0
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Push attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"
            git checkout -- . 2>/dev/null || true
            git clean -fd 2>/dev/null || true
            if git pull --rebase -X theirs origin main; then
              if git push origin main; then
                echo "Successfully pushed changes"
                exit 0
              fi
            else
              echo "Rebase failed, aborting and retrying..."
              git rebase --abort 2>/dev/null || true
            fi
            RETRY_COUNT=$((RETRY_COUNT + 1))
            if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
              WAIT_TIME=$((10 + RANDOM % 20))
              echo "Waiting $WAIT_TIME seconds before retry..."
              sleep $WAIT_TIME
              git fetch origin main
            fi
          done
          echo "Failed to push after $MAX_RETRIES attempts"
          exit 1

  # Step 4: Rebuild reviews.json after all batches and aggregators complete
  rebuild:
    needs: [prepare, gather-reviews, scrape-aggregators]
    if: always() && needs.gather-reviews.result != 'cancelled'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (latest, after all batches pushed)
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm ci

      - name: Rebuild reviews.json
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: node scripts/rebuild-all-reviews.js

      - name: Commit rebuilt reviews.json
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          git add data/reviews.json data/critic-registry.json data/audit/
          if git diff --staged --quiet; then
            echo "No changes to reviews.json"
          else
            git commit -m "data: Auto-rebuild reviews.json after gather (${{ inputs.shows }})"
            for i in 1 2 3 4 5; do
              if git push origin main; then
                echo "Push succeeded on attempt $i"
                break
              fi
              echo "Retry $i: Waiting before retry..."
              sleep $((RANDOM % 10 + 5))
              git checkout -- . 2>/dev/null || true
              git clean -fd 2>/dev/null || true
              git pull --rebase -X theirs origin main || { git rebase --abort 2>/dev/null || true; git pull --no-rebase -X ours origin main; }
            done
          fi

  # Step 4: Update related issues
  update-issues:
    needs: [gather-reviews]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Update issue (if exists)
        uses: actions/github-script@v7
        with:
          script: |
            // Find and comment on the related new-show issue
            const shows = '${{ inputs.shows }}'.split(',');

            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'new-show,needs-review-data',
              state: 'open',
            });

            for (const issue of issues.data) {
              // Check if this issue mentions any of our shows
              const matchesShow = shows.some(slug =>
                issue.body?.includes(slug)
              );

              if (matchesShow) {
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: issue.number,
                  body: `ðŸ¤– **Review Data Gathering Attempted**\n\nWorkflow run: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}\n\nShows processed: ${shows.join(', ')}`
                });
              }
            }
