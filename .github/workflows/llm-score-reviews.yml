name: LLM Score Reviews

on:
  # Manual trigger with options
  workflow_dispatch:
    inputs:
      show:
        description: 'Show slug to process (leave empty for all)'
        required: false
        default: ''
      limit:
        description: 'Max reviews to process (leave empty for no limit)'
        required: false
        default: ''
      model:
        description: 'Claude model to use'
        required: false
        default: 'sonnet'
        type: choice
        options:
          - sonnet
          - haiku
      run_calibration:
        description: 'Run calibration after scoring'
        required: false
        default: true
        type: boolean
      run_validation:
        description: 'Run aggregator validation after scoring'
        required: false
        default: true
        type: boolean
      dry_run:
        description: 'Dry run (no file changes)'
        required: false
        default: false
        type: boolean

env:
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

jobs:
  score-reviews:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build CLI arguments
        id: build-args
        run: |
          ARGS=""

          # Show filter
          if [ -n "${{ github.event.inputs.show }}" ]; then
            ARGS="$ARGS --show=${{ github.event.inputs.show }}"
          else
            ARGS="$ARGS --all"
          fi

          # Limit
          if [ -n "${{ github.event.inputs.limit }}" ]; then
            ARGS="$ARGS --limit=${{ github.event.inputs.limit }}"
          fi

          # Model
          ARGS="$ARGS --model=${{ github.event.inputs.model }}"

          # Calibration
          if [ "${{ github.event.inputs.run_calibration }}" == "true" ]; then
            ARGS="$ARGS --calibrate"
          fi

          # Validation
          if [ "${{ github.event.inputs.run_validation }}" == "true" ]; then
            ARGS="$ARGS --validate"
          fi

          # Dry run
          if [ "${{ github.event.inputs.dry_run }}" == "true" ]; then
            ARGS="$ARGS --dry-run"
          fi

          # Always verbose in CI
          ARGS="$ARGS --verbose"

          echo "args=$ARGS" >> $GITHUB_OUTPUT

      - name: Run LLM scoring pipeline
        run: |
          npx ts-node --project scripts/tsconfig.json scripts/llm-scoring/index.ts ${{ steps.build-args.outputs.args }}

      - name: Check for changes
        id: check-changes
        if: ${{ github.event.inputs.dry_run != 'true' }}
        run: |
          git add -A
          if git diff --staged --quiet; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
            git diff --staged --stat
          fi

      - name: Commit and push changes
        if: ${{ steps.check-changes.outputs.has_changes == 'true' }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Build commit message
          SHOW_MSG=""
          if [ -n "${{ github.event.inputs.show }}" ]; then
            SHOW_MSG=" for ${{ github.event.inputs.show }}"
          fi

          git commit -m "feat: LLM score reviews${SHOW_MSG}

          Model: ${{ github.event.inputs.model }}
          Triggered by: @${{ github.actor }}

          Co-Authored-By: Claude <noreply@anthropic.com>"

          # Pull and rebase before pushing to handle concurrent changes
          git pull --rebase origin ${{ github.ref_name }} || true
          git push
