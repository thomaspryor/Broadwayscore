name: Collect Review Texts

on:
  schedule:
    # Nightly at 2 AM UTC (9 PM EST) - automated backfill of truncated/stub reviews
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of reviews to process per batch'
        required: false
        default: '10'
      max_reviews:
        description: 'Maximum total reviews to process (0 = all)'
        required: false
        default: '100'
      priority:
        description: 'Priority filter (tier1, all)'
        required: false
        default: 'all'
      show_filter:
        description: 'Only process specific show (leave empty for all)'
        required: false
        default: ''
      aggressive:
        description: 'Skip Playwright for known-blocked sites (true/false)'
        required: false
        default: 'false'
      retry_failed:
        description: 'Retry previously failed reviews (true/false)'
        required: false
        default: 'true'
      stealth_proxy:
        description: 'Use ScrapingBee stealth proxy - costs 75 credits/request but better CAPTCHA bypass'
        required: false
        default: 'false'
      parallel:
        description: 'Run parallel jobs by outlet tier (true/false)'
        required: false
        default: 'false'
      archive_first:
        description: 'Try Archive.org first for older reviews (true/false)'
        required: false
        default: 'true'
      browserbase_enabled:
        description: 'Enable Browserbase tier for CAPTCHA-heavy sites (costs ~$0.10/session)'
        required: false
        default: 'true'
      browserbase_max_sessions:
        description: 'Max Browserbase sessions per run (default 20, daily cap 30)'
        required: false
        default: '20'
      content_tier:
        description: 'Filter by content tier: excerpt, truncated, needs-rescrape (empty = all)'
        required: false
        default: ''
      chain:
        description: 'Auto-trigger next batch when this one finishes (true/false)'
        required: false
        default: 'false'
      remaining_batches:
        description: 'Remaining batches for chaining (decrements each run, 0 = stop)'
        required: false
        default: '0'
      chain_browserbase_budget:
        description: 'Remaining Browserbase sessions across chained runs (daily cap awareness)'
        required: false
        default: '30'

## PARALLEL RUNS: Max 5 simultaneous runs recommended.
## Browserbase daily limit is 30 sessions; default 5/run × 5 runs = 25 (safe).
## Launching >5 runs will cause Browserbase 429 rate limits.

jobs:
  # Sequential single-job mode (default)
  collect-reviews-single:
    if: ${{ inputs.parallel != 'true' }}
    runs-on: ubuntu-latest
    timeout-minutes: 180
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Install Playwright browsers
        run: npx playwright install chromium

      - name: Create directories
        run: |
          mkdir -p data/archives/reviews
          mkdir -p data/audit/validation
          mkdir -p data/collection-state

      - name: Clear progress state for parallel runs
        if: ${{ inputs.show_filter != '' }}
        run: |
          echo "Filtered run (show_filter set) - clearing progress state for independent parallel execution"
          rm -f data/collection-state/progress.json

      - name: Configure git for incremental commits
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

      - name: Run review collection
        id: collect
        env:
          NYT_EMAIL: ${{ secrets.NYT_EMAIL }}
          NYT_PASSWORD: ${{ secrets.NYTIMES_PASSWORD }}
          VULTURE_EMAIL: ${{ secrets.VULTURE_EMAIL }}
          VULTURE_PASSWORD: ${{ secrets.VULTURE_PASSWORD }}
          WAPO_EMAIL: ${{ secrets.WAPO_EMAIL }}
          WAPO_PASSWORD: ${{ secrets.WASHPOST_PASSWORD }}
          WSJ_EMAIL: ${{ secrets.WSJ_EMAIL }}
          WSJ_PASSWORD: ${{ secrets.WSJ_PASSWORD }}
          SCRAPINGBEE_API_KEY: ${{ secrets.SCRAPINGBEE_API_KEY }}
          BRIGHTDATA_TOKEN: ${{ secrets.BRIGHTDATA_TOKEN }}
          BRIGHTDATA_ZONE: mcp_unlocker
          BROWSERBASE_API_KEY: ${{ secrets.BROWSERBASE_API_KEY }}
          BROWSERBASE_PROJECT_ID: ${{ secrets.BROWSERBASE_PROJECT_ID }}
          BROWSERBASE_ENABLED: ${{ inputs.browserbase_enabled }}
          BROWSERBASE_MAX_SESSIONS_PER_RUN: ${{ inputs.browserbase_max_sessions }}
          BATCH_SIZE: ${{ inputs.batch_size }}
          MAX_REVIEWS: ${{ inputs.max_reviews }}
          PRIORITY: ${{ inputs.priority }}
          SHOW_FILTER: ${{ inputs.show_filter }}
          RETRY_FAILED: ${{ inputs.retry_failed }}
          ARCHIVE_FIRST: ${{ inputs.archive_first }}
          CONTENT_TIER_FILTER: ${{ inputs.content_tier }}
        run: |
          ARGS=""
          if [ "${{ inputs.aggressive }}" = "true" ]; then
            ARGS="$ARGS --aggressive"
          fi
          if [ "${{ inputs.stealth_proxy }}" = "true" ]; then
            ARGS="$ARGS --stealth-proxy"
          fi
          node scripts/collect-review-texts.js $ARGS

      - name: Validate data before commit
        run: node scripts/validate-data.js
        continue-on-error: true

      - name: Check for large files
        uses: ./.github/actions/check-file-sizes

      - name: Final commit and push
        id: push
        run: |
          git add data/review-texts/ data/archives/reviews/ data/audit/ data/collection-state/ || true
          if git diff --staged --quiet; then
            echo "No changes to commit"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            TIER_LABEL="${{ inputs.content_tier }}"
            JOB_LABEL="single job${TIER_LABEL:+ — $TIER_LABEL}"
            git commit -m "feat: Collect review texts ($JOB_LABEL)

          Co-Authored-By: GitHub Action <action@github.com>"
            git pull --rebase origin main || {
              git rebase --abort || true
              git pull --no-rebase -X ours origin main
            }
            git push
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Rebuild reviews.json
        if: steps.push.outputs.has_changes == 'true'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: node scripts/rebuild-all-reviews.js
        continue-on-error: true

      - name: Commit rebuilt reviews.json
        if: steps.push.outputs.has_changes == 'true'
        run: |
          git add data/reviews.json data/critic-registry.json data/audit/
          if git diff --staged --quiet; then
            echo "No changes to reviews.json"
          else
            git commit -m "data: Auto-rebuild reviews.json"
            git pull --rebase origin main || {
              git rebase --abort 2>/dev/null || true
              git pull --no-rebase -X ours origin main
            }
            git push || true
          fi

      - name: Upload collection report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: collection-report
          path: |
            data/audit/validation/collection-report-*.json
            data/collection-state/progress.json
          retention-days: 30

      - name: Count remaining reviews needing text
        if: ${{ inputs.chain == 'true' }}
        id: count-remaining
        run: |
          REMAINING=$(node -e "
            const fs = require('fs'), path = require('path');
            const base = 'data/review-texts';
            const dirs = fs.readdirSync(base).filter(d => fs.statSync(path.join(base, d)).isDirectory());
            let n = 0;
            dirs.forEach(d => {
              fs.readdirSync(path.join(base, d)).filter(f => f.endsWith('.json')).forEach(f => {
                try {
                  const r = JSON.parse(fs.readFileSync(path.join(base, d, f), 'utf8'));
                  if (r.url && !r.fullText) n++;
                } catch(e) {}
              });
            });
            console.log(n);
          ")
          echo "remaining=$REMAINING" >> $GITHUB_OUTPUT
          echo "Reviews still needing full text: $REMAINING"

      - name: Chain next collection batch
        if: ${{ inputs.chain == 'true' && steps.count-remaining.outputs.remaining > 10 }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          BATCHES_LEFT=${{ inputs.remaining_batches }}
          if [ "$BATCHES_LEFT" -le 0 ] 2>/dev/null; then
            echo "No remaining batches. Chain complete."
            exit 0
          fi

          NEXT_BATCHES=$((BATCHES_LEFT - 1))

          # Browserbase budget tracking across chain
          BB_BUDGET=${{ inputs.chain_browserbase_budget }}
          BB_PER_RUN=${{ inputs.browserbase_max_sessions }}
          BB_PER_RUN="${BB_PER_RUN:-20}"
          NEXT_BB_BUDGET=$((BB_BUDGET - BB_PER_RUN))

          # Determine Browserbase settings for next run
          if [ "$NEXT_BB_BUDGET" -le 0 ]; then
            echo "Browserbase daily budget exhausted. Next run without Browserbase."
            NEXT_BB_ENABLED="false"
            NEXT_BB_SESSIONS="0"
            NEXT_BB_BUDGET="0"
          else
            NEXT_BB_ENABLED="true"
            # Cap next run's sessions to remaining budget
            if [ "$BB_PER_RUN" -gt "$NEXT_BB_BUDGET" ]; then
              NEXT_BB_SESSIONS="$NEXT_BB_BUDGET"
            else
              NEXT_BB_SESSIONS="$BB_PER_RUN"
            fi
          fi

          echo "Dispatching next batch..."
          echo "  Remaining batches after this: $NEXT_BATCHES"
          echo "  Browserbase budget remaining: $NEXT_BB_BUDGET sessions"
          echo "  Browserbase this run: $NEXT_BB_ENABLED ($NEXT_BB_SESSIONS sessions)"
          echo "  Reviews still needing text: ${{ steps.count-remaining.outputs.remaining }}"

          TIER_FILTER="${{ inputs.content_tier }}"

          gh workflow run "Collect Review Texts" \
            -f max_reviews=${{ inputs.max_reviews }} \
            -f batch_size=${{ inputs.batch_size }} \
            -f browserbase_enabled="$NEXT_BB_ENABLED" \
            -f browserbase_max_sessions="$NEXT_BB_SESSIONS" \
            -f retry_failed=${{ inputs.retry_failed }} \
            -f archive_first=${{ inputs.archive_first }} \
            -f content_tier="$TIER_FILTER" \
            -f chain=true \
            -f remaining_batches="$NEXT_BATCHES" \
            -f chain_browserbase_budget="$NEXT_BB_BUDGET"

          echo "Next batch dispatched successfully."

  # Parallel multi-job mode (matrix strategy)
  collect-reviews-parallel:
    if: ${{ inputs.parallel == 'true' }}
    runs-on: ubuntu-latest
    timeout-minutes: 120
    permissions:
      contents: write

    strategy:
      fail-fast: false
      matrix:
        outlet_tier: [tier1, tier2, tier3]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Install Playwright browsers
        run: npx playwright install chromium

      - name: Create directories
        run: |
          mkdir -p data/archives/reviews
          mkdir -p data/audit/validation
          mkdir -p data/collection-state

      - name: Clear progress state for parallel runs
        run: |
          echo "Parallel matrix run - clearing progress state for independent execution"
          rm -f data/collection-state/progress.json

      - name: Configure git for incremental commits
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

      - name: Run review collection for ${{ matrix.outlet_tier }}
        env:
          NYT_EMAIL: ${{ secrets.NYT_EMAIL }}
          NYT_PASSWORD: ${{ secrets.NYTIMES_PASSWORD }}
          VULTURE_EMAIL: ${{ secrets.VULTURE_EMAIL }}
          VULTURE_PASSWORD: ${{ secrets.VULTURE_PASSWORD }}
          WAPO_EMAIL: ${{ secrets.WAPO_EMAIL }}
          WAPO_PASSWORD: ${{ secrets.WASHPOST_PASSWORD }}
          WSJ_EMAIL: ${{ secrets.WSJ_EMAIL }}
          WSJ_PASSWORD: ${{ secrets.WSJ_PASSWORD }}
          SCRAPINGBEE_API_KEY: ${{ secrets.SCRAPINGBEE_API_KEY }}
          BRIGHTDATA_TOKEN: ${{ secrets.BRIGHTDATA_TOKEN }}
          BRIGHTDATA_ZONE: mcp_unlocker
          BROWSERBASE_API_KEY: ${{ secrets.BROWSERBASE_API_KEY }}
          BROWSERBASE_PROJECT_ID: ${{ secrets.BROWSERBASE_PROJECT_ID }}
          BROWSERBASE_ENABLED: ${{ inputs.browserbase_enabled }}
          BROWSERBASE_MAX_SESSIONS_PER_RUN: ${{ inputs.browserbase_max_sessions }}
          BATCH_SIZE: ${{ inputs.batch_size }}
          MAX_REVIEWS: ${{ inputs.max_reviews }}
          OUTLET_TIER: ${{ matrix.outlet_tier }}
          SHOW_FILTER: ${{ inputs.show_filter }}
          RETRY_FAILED: ${{ inputs.retry_failed }}
          ARCHIVE_FIRST: ${{ inputs.archive_first }}
          CONTENT_TIER_FILTER: ${{ inputs.content_tier }}
        run: |
          ARGS=""
          if [ "${{ inputs.aggressive }}" = "true" ]; then
            ARGS="$ARGS --aggressive"
          fi
          if [ "${{ inputs.stealth_proxy }}" = "true" ]; then
            ARGS="$ARGS --stealth-proxy"
          fi
          node scripts/collect-review-texts.js $ARGS

      - name: Validate data before commit
        run: node scripts/validate-data.js
        continue-on-error: true

      - name: Commit and push changes for ${{ matrix.outlet_tier }}
        run: |
          git add data/review-texts/ data/archives/reviews/
          if git diff --staged --quiet; then
            echo "No changes to commit for ${{ matrix.outlet_tier }}"
          else
            git commit -m "feat: Collect review texts (${{ matrix.outlet_tier }})

          Co-Authored-By: GitHub Action <action@github.com>"

            # Robust retry loop for parallel job conflicts
            for i in 1 2 3 4 5; do
              git pull --rebase origin main && git push && break || {
                echo "Retry $i: Waiting before retry..."
                sleep $((RANDOM % 10 + 5))
                git rebase --abort 2>/dev/null || true
                git pull --no-rebase -X ours origin main
              }
            done
          fi

      - name: Upload collection report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: collection-report-${{ matrix.outlet_tier }}
          path: |
            data/audit/validation/collection-report-*.json
          retention-days: 30

  # Trigger rebuild after all parallel jobs complete
  trigger-rebuild-parallel:
    if: ${{ inputs.parallel == 'true' }}
    needs: collect-reviews-parallel
    runs-on: ubuntu-latest
    steps:
      - name: Trigger reviews.json rebuild
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh workflow run "Rebuild Reviews Data" \
            -R "${{ github.repository }}" \
            -f reason="Auto-triggered after Collect Review Texts (parallel)"

