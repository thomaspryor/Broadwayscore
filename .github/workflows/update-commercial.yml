name: Update Commercial Data

on:
  schedule:
    - cron: '0 16 * * 3'  # Wednesday 4pm UTC / 11am ET
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Dry run (no changes committed)'
        required: false
        type: boolean
        default: false
      gather_only:
        description: 'Gather data only (no AI analysis)'
        required: false
        type: boolean
        default: false

jobs:
  update-commercial:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Configure git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Run commercial data update
        id: update
        env:
          SCRAPINGBEE_API_KEY: ${{ secrets.SCRAPINGBEE_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          # Subscription credentials for paywalled trade press sites
          NYT_EMAIL: ${{ secrets.NYT_EMAIL }}
          NYTIMES_PASSWORD: ${{ secrets.NYTIMES_PASSWORD }}
          VULTURE_EMAIL: ${{ secrets.VULTURE_EMAIL }}
          VULTURE_PASSWORD: ${{ secrets.VULTURE_PASSWORD }}
        run: |
          ARGS="--gather-all --gather-trade-full"
          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            ARGS="$ARGS --dry-run"
          fi
          if [ "${{ github.event.inputs.gather_only }}" = "true" ]; then
            ARGS="$ARGS --gather-only"
          fi
          # Add SEC gathering if enabled and credentials available
          if [ -n "$SEC_EDGAR_ENABLED" ] && [ "$SEC_EDGAR_ENABLED" != "false" ]; then
            ARGS="$ARGS --gather-sec"
          fi
          node scripts/update-commercial-data.js $ARGS
        # Continue even if there are Deep Research conflicts (they're logged, not failures)
        continue-on-error: true

      - name: Validate data
        if: always()
        run: npm run test:data

      - name: Build site
        if: always()
        run: npm run build
        env:
          NODE_ENV: production
        continue-on-error: true

      - name: Commit and push changes
        if: always()
        run: |
          git add data/commercial.json data/commercial-changelog.json

          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            WEEK_ENDING=$(node -e "try{const d=require('./data/commercial-changelog.json');const e=d.entries;console.log(e.length?e[e.length-1].weekEnding:'unknown')}catch(e){console.log('unknown')}")
            git commit -m "data: Update commercial data for week ending $WEEK_ENDING

          Automated weekly update of commercial scorecard data.

          Co-Authored-By: github-actions[bot] <github-actions[bot]@users.noreply.github.com>"

            MAX_RETRIES=5
            RETRY_COUNT=0
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              echo "Push attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"
              git checkout -- . 2>/dev/null || true
              git clean -fd 2>/dev/null || true
              if git pull --rebase -X theirs origin main; then
                if git push origin main; then
                  echo "Successfully pushed changes"
                  break
                fi
              else
                echo "Rebase failed, aborting and retrying..."
                git rebase --abort 2>/dev/null || true
              fi
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                WAIT_TIME=$((10 + RANDOM % 20))
                echo "Waiting $WAIT_TIME seconds before retry..."
                sleep $WAIT_TIME
                git fetch origin main
              fi
            done
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Commercial Data Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f data/commercial-changelog.json ]; then
            # Extract the latest entry's stats
            node -e "
              const changelog = require('./data/commercial-changelog.json');
              const entries = changelog.entries || [];
              const latest = entries[entries.length - 1];
              if (latest) {
                console.log('- **Date:** ' + (latest.date || latest.weekEnding || 'unknown'));
                console.log('- **Changes Applied:** ' + (latest.changesApplied || 0));
                console.log('- **Changes Flagged:** ' + (latest.changesFlagged || 0));
                console.log('- **Deep Research Conflicts:** ' + (latest.deepResearchConflicts || 0));
                if (latest.deepResearchConflicts > 0) {
                  console.log('');
                  console.log('### ⚠️ Deep Research Conflicts Blocked');
                  console.log('');
                  console.log('The following changes were blocked by Deep Research protection:');
                  if (latest.blocked) {
                    for (const b of latest.blocked) {
                      console.log('- **' + b.slug + '.' + b.field + '**: ' + (b.discrepancy || 'conflict detected'));
                    }
                  }
                }
              } else {
                console.log('No changelog entries found.');
              }
            " >> $GITHUB_STEP_SUMMARY
          fi

      - name: Create issue on failure
        if: failure() && github.event_name == 'schedule'
        uses: actions/github-script@v7
        with:
          script: |
            const title = 'Commercial Data Update Failed';
            const body = `## Commercial Data Update Failed

            The weekly commercial data update encountered an error.

            **Run:** [${context.runId}](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            **Time:** ${new Date().toISOString()}

            Please check the workflow logs for details.

            ### Common Issues
            - ScrapingBee API rate limit or key issue
            - Reddit posts not found (u/Boring_Waltz_9545 may have skipped a week)
            - Claude API error
            - Data validation failure

            ---
            *This issue was automatically created by the commercial data workflow.*`;

            // Check if similar issue already exists
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'automated,bug'
            });

            const existingIssue = issues.data.find(i => i.title === title);
            if (!existingIssue) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['automated', 'bug', 'commercial']
              });
            }
